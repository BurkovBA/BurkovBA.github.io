---
title: Engineering aspects of deep learning
date: "2021-12-06T00:00:00.284Z"
tags: ["programming"]
cover: "./cuda.jpeg"
description: Here I briefly discuss some engineering aspects, related to deep learning, such as floating-point precision, video memory, PCIe bus rate etc. 
---

References
----------
 - https://blog.slavv.com/titan-rtx-quality-time-with-the-top-turing-gpu-fe110232a28e - Slav on RTX video cards
 - https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html - long post by NVidia on mixed precision
 - https://en.wikipedia.org/wiki/NVLink - NVLink
 - https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9926-tensor-core-performance-the-ultimate-guide.pdf - NVidia presentation on Tensor Cores
 - https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/ - NVidia on Tensor Cores and quantization
 - https://flax.readthedocs.io/en/latest/notebooks/jax_for_the_impatient.html - JAX
 - https://arxiv.org/abs/1609.04836 - on large-batch training
 - https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc - PyTorch autograd mechanics
 - https://arxiv.org/pdf/2004.08900.pdf - brief overview of model training costs
 - http://neuralnetworksanddeeplearning.com/chap2.html - long read on backprop (more of a theory)
 - https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example - a practical example of backpropagation run